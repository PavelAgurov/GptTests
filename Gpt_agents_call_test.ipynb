{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML9W2CN2DrSpJX4WHS7kJQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavelAgurov/GptTests/blob/main/Gpt_agents_call_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple test with 2 agents\n",
        "\n",
        "First agent should ask to call second one.\n",
        "Second one provide final answer.\n",
        "\n",
        "Gpt can call second agent directly when it's clear.\n",
        "\n",
        "Interesting that Gpt can decided to call or not call second tool even after instruction from first tool."
      ],
      "metadata": {
        "id": "Fa1TvteftwvY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EM1a2hDkZKf"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install colab_env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load from vars.env\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "colab_env.envvar_handler.envload()\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv8eH3I0kghz",
        "outputId": "a94d7188-cb3a-478f-a567-817b850991e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key= OPENAI_API_KEY,\n",
        "    model_name=\"gpt-3.5-turbo\", \n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "9XiOGZG9kpom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783464c7-c53c-4574-c476-14f3de16772d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.utilities.powerbi:Could not import azure.core python package.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this agent should answer any question, but ask to call second tool\n",
        "\n",
        "from langchain.agents import Tool\n",
        "\n",
        "def my_agent(query : str):\n",
        "  print('\\nTOOL[my_agent]:', query)\n",
        "  return f\"Call 'my_number' to get final answer\"\n",
        "\n",
        "my_agent_tool = Tool(\n",
        "    name = \"my_agent\", \n",
        "    func=my_agent, \n",
        "    description=\"useful for answer the question\"\n",
        ")"
      ],
      "metadata": {
        "id": "hYmnjwM7ksWf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "import random\n",
        "\n",
        "def my_number(query : str):\n",
        "  print('\\nTOOL[my_number]:', query)\n",
        "  n = random.randint(0, 10)\n",
        "  return f\"{n}\"\n",
        "\n",
        "my_number_tool = Tool(\n",
        "    name = \"my_number\", \n",
        "    func=my_number, \n",
        "    description=\"useful to answer about number\",\n",
        "    return_direct=True # output returned directly to the user\n",
        ")"
      ],
      "metadata": {
        "id": "dcDWCJUfmyVJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [my_agent_tool, my_number_tool]"
      ],
      "metadata": {
        "id": "9BB0l-zNnDvR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools, \n",
        "    llm, \n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "oFF-IGTtky_A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "For this new prompt, you only have access to the tools 'my_agent' and 'my_number'. Only call those tools. \n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"question\"], template= prompt_template)"
      ],
      "metadata": {
        "id": "VV1Jg5trqozY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt_template.format(question = \"Say me any number\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "9xgsVBFak8k9",
        "outputId": "d0fda62b-af93-4a71-f236-2d96846deac0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to use 'my_number' to answer this question.\n",
            "Action: my_number\n",
            "Action Input: None\u001b[0m\n",
            "TOOL[my_number]: None\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m7\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt_template.format(question = \"Hi\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "BWfL-32hr_ik",
        "outputId": "0b7d3246-9494-4768-f891-d52f039ddd95"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThis is not a question, so I will not need to use any tools.\n",
            "Final Answer: N/A\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N/A'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt_template.format(question = \"How you doing?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Trm4pblTsEhR",
        "outputId": "8d7b7202-68ef-4af0-d515-a446c42030f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThis is a casual greeting and doesn't require a specific answer.\n",
            "Action: my_agent\n",
            "Action Input: \"How you doing?\"\u001b[0m\n",
            "TOOL[my_agent]: How you doing?\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mCall 'my_number' to get final answer\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mWait, 'my_number' is not a tool that can answer this question. I need to use 'my_agent' to respond appropriately.\n",
            "Action: my_agent\n",
            "Action Input: \"I'm doing well, thank you. How about you?\"\u001b[0m\n",
            "TOOL[my_agent]: I'm doing well, thank you. How about you?\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mCall 'my_number' to get final answer\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThere is no need to call 'my_number' as this question does not require a numerical answer.\n",
            "Final Answer: \"I'm doing well, thank you. How about you?\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"I\\'m doing well, thank you. How about you?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt_template.format(question = \"Do you have number?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "q9QTd7K6sXjr",
        "outputId": "aec99f65-1fda-440f-ae4f-7e4b1d88355f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to check if I have a number available to answer this question.\n",
            "Action: my_number\n",
            "Action Input: None\u001b[0m\n",
            "TOOL[my_number]: None\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m10\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt_template.format(question = \"What is temperature in Germany today?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "7IDAUyr_uoiB",
        "outputId": "40216a4d-b1c2-4b81-8c16-870fc058456c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI don't have direct access to the temperature in Germany, so I need to find a way to get that information using my tools.\n",
            "Action: my_agent\n",
            "Action Input: \"What is the current temperature in Germany?\"\u001b[0m\n",
            "TOOL[my_agent]: What is the current temperature in Germany?\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mCall 'my_number' to get final answer\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mSince 'my_agent' doesn't have direct access to the temperature in Germany, it must have asked a search engine or a weather website for the information.\n",
            "Action: my_number\n",
            "Action Input: \"What is the temperature in Germany today?\"\u001b[0m\n",
            "TOOL[my_number]: What is the temperature in Germany today?\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m3\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}